{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cy1IGAK7pJpz"
   },
   "source": [
    "### This is a simple LGB baseline. You can work for feature engineering.\n",
    "### The seed is 42, which will bring good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-19T11:39:13.476656Z",
     "iopub.status.busy": "2023-02-19T11:39:13.476206Z",
     "iopub.status.idle": "2023-02-19T11:39:13.486675Z",
     "shell.execute_reply": "2023-02-19T11:39:13.485328Z",
     "shell.execute_reply.started": "2023-02-19T11:39:13.476619Z"
    },
    "id": "Xs3TRi_HpJqA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import lightgbm as lgb\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#from lightgbm import LGBMRegressor\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import tqdm\n",
    "\n",
    "n_fold = 10\n",
    "group_gap = 31\n",
    "seed = 42\n",
    "\n",
    "#Chris' paths:\n",
    "#TRAIN_MARKET_PATH = '../HKU_QIS/first_round_train_market_data.csv'\n",
    "#TRAIN_FUNADMENTAL_PATH = '../HKU_QIS/first_round_train_fundamental_data.csv'\n",
    "#TRAIN_RETURN_PATH = '../HKU_QIS/first_round_train_return_data.csv'\n",
    "\n",
    "#TEST_MARKET_PATH = '../HKU_QIS/qids_package/first_round_test_market_data.csv'\n",
    "#TEST_FUNADMENTAL_PATH = '../HKU_QIS/qids_package/first_round_test_fundamental_data.csv'\n",
    "\n",
    "#Freya's paths:\n",
    "TRAIN_MARKET_PATH = '/Users/75717/Downloads/273_Washu/first_round_train_market_data.csv'\n",
    "TRAIN_FUNADMENTAL_PATH = '/Users/75717/Downloads/273_Washu/first_round_train_fundamental_data.csv'\n",
    "TRAIN_RETURN_PATH = '/Users/75717/Downloads/273_Washu/first_round_train_return_data.csv'\n",
    "\n",
    "TEST_MARKET_PATH = '/Users/75717/Downloads/273_Washu/first_round_test_market_data.csv'\n",
    "TEST_FUNADMENTAL_PATH = '/Users/75717/Downloads/273_Washu/first_round_test_fundamental_data.csv'\n",
    "\n",
    "#Cynthia's paths:\n",
    "#TRAIN_MARKET_PATH = '/content/drive/MyDrive/hku_qis/hku-qids-2023-quantitative-investment-competition/first_round_train_market_data.csv'\n",
    "#TRAIN_FUNADMENTAL_PATH = '/content/drive/MyDrive/hku_qis/hku-qids-2023-quantitative-investment-competition/first_round_train_fundamental_data.csv'\n",
    "#TRAIN_RETURN_PATH = '/content/drive/MyDrive/hku_qis/hku-qids-2023-quantitative-investment-competition/first_round_train_return_data.csv'\n",
    "\n",
    "#TEST_MARKET_PATH = '/content/drive/MyDrive/hku_qis/hku-qids-2023-quantitative-investment-competition/first_round_test_market_data.csv'\n",
    "#TEST_FUNADMENTAL_PATH = '/content/drive/MyDrive/hku_qis/hku-qids-2023-quantitative-investment-competition/first_round_test_fundamental_data.csv'\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-19T11:39:14.994016Z",
     "iopub.status.busy": "2023-02-19T11:39:14.993573Z",
     "iopub.status.idle": "2023-02-19T11:39:20.332244Z",
     "shell.execute_reply": "2023-02-19T11:39:20.331197Z",
     "shell.execute_reply.started": "2023-02-19T11:39:14.993976Z"
    },
    "id": "RdPuh_tdpJqB"
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "df_train_market = pd.read_csv(TRAIN_MARKET_PATH)\n",
    "df_train_return = pd.read_csv(TRAIN_RETURN_PATH)\n",
    "df_train_fundamental = pd.read_csv(TRAIN_FUNADMENTAL_PATH)\n",
    "\n",
    "df_test_market = pd.read_csv(TEST_MARKET_PATH)\n",
    "df_test_fundamental = pd.read_csv(TEST_FUNADMENTAL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-19T11:39:20.334662Z",
     "iopub.status.busy": "2023-02-19T11:39:20.33424Z",
     "iopub.status.idle": "2023-02-19T11:40:01.127892Z",
     "shell.execute_reply": "2023-02-19T11:40:01.12668Z",
     "shell.execute_reply.started": "2023-02-19T11:39:20.334626Z"
    },
    "id": "Jv4-5wXJpJqB"
   },
   "outputs": [],
   "source": [
    "#merge train dataset and test dataset\n",
    "def split_time(x):\n",
    "    df1 = x['date_time'].str.split('d', expand=True)\n",
    "    df1.columns=['code','s']\n",
    "    code = df1['code']\n",
    "    df1 = df1['s'].str.split('p', expand=True)\n",
    "    df1.columns=['day','time_step']\n",
    "    df2 = x['date_time'].str.rsplit('p', expand=True)\n",
    "    df2.columns=['day_s','s']\n",
    "    df1['day_s'] = df2['day_s']\n",
    "    df1['code'] = code\n",
    "    x = pd.concat([x,df1],axis=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "df_train_market = split_time(df_train_market)\n",
    "df = pd.merge(df_train_fundamental,df_train_market, left_on='date_time',right_on='day_s')  \n",
    "df = pd.merge(df,df_train_return, left_on='day_s',right_on='date_time')  \n",
    "\n",
    "df_test_market = split_time(df_test_market)\n",
    "test = pd.merge(df_test_fundamental,df_test_market, left_on='date_time',right_on='day_s')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-19T11:40:01.129791Z",
     "iopub.status.busy": "2023-02-19T11:40:01.129418Z",
     "iopub.status.idle": "2023-02-19T11:40:05.177691Z",
     "shell.execute_reply": "2023-02-19T11:40:05.176402Z",
     "shell.execute_reply.started": "2023-02-19T11:40:01.129759Z"
    },
    "id": "_XWIEwTopJqC"
   },
   "outputs": [],
   "source": [
    "#drop duplicates\n",
    "df = df.drop_duplicates(subset='day_s', keep='last').reset_index(drop=True)\n",
    "test = test.drop_duplicates(subset='day_s', keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-19T11:40:05.180387Z",
     "iopub.status.busy": "2023-02-19T11:40:05.179995Z",
     "iopub.status.idle": "2023-02-19T11:40:05.193826Z",
     "shell.execute_reply": "2023-02-19T11:40:05.19235Z",
     "shell.execute_reply.started": "2023-02-19T11:40:05.180348Z"
    },
    "id": "QUpx57DzpJqC"
   },
   "outputs": [],
   "source": [
    "def correlation(a, train_data):\n",
    "    \n",
    "    b = train_data.get_label()\n",
    "    \n",
    "    a = np.ravel(a)\n",
    "    b = np.ravel(b)\n",
    "\n",
    "    len_data = len(a)\n",
    "    mean_a = np.sum(a) / len_data\n",
    "    mean_b = np.sum(b) / len_data\n",
    "    var_a = np.sum(np.square(a - mean_a)) / len_data\n",
    "    var_b = np.sum(np.square(b - mean_b)) / len_data\n",
    "\n",
    "    cov = np.sum((a * b))/len_data - mean_a*mean_b\n",
    "    corr = cov / np.sqrt(var_a * var_b)\n",
    "\n",
    "    return 'corr', corr, True\n",
    "\n",
    "# For CV score calculation\n",
    "def corr_score(pred, valid):\n",
    "    len_data = len(pred)\n",
    "    mean_pred = np.sum(pred) / len_data\n",
    "    mean_valid = np.sum(valid) / len_data\n",
    "    var_pred = np.sum(np.square(pred - mean_pred)) / len_data\n",
    "    var_valid = np.sum(np.square(valid - mean_valid)) / len_data\n",
    "\n",
    "    cov = np.sum((pred * valid))/len_data - mean_pred*mean_valid\n",
    "    corr = cov / np.sqrt(var_pred * var_valid)\n",
    "\n",
    "    return corr\n",
    "\n",
    "# For CV score calculation\n",
    "def wcorr_score(pred, valid, weight):\n",
    "    len_data = len(pred)\n",
    "    sum_w = np.sum(weight)\n",
    "    mean_pred = np.sum(pred * weight) / sum_w\n",
    "    mean_valid = np.sum(valid * weight) / sum_w\n",
    "    var_pred = np.sum(weight * np.square(pred - mean_pred)) / sum_w\n",
    "    var_valid = np.sum(weight * np.square(valid - mean_valid)) / sum_w\n",
    "\n",
    "    cov = np.sum((pred * valid * weight)) / sum_w - mean_pred*mean_valid\n",
    "    corr = cov / np.sqrt(var_pred * var_valid)\n",
    "\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for normalizing data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#because these time variables are not number, they cannot be scaled\n",
    "col_train=[i for i in df.columns if i not in ['date_time_x', 'date_time_y', 'day', 'time_step', 'day_s', 'code', 'date_time','return']]\n",
    "timer_train=df.loc[:,['date_time_x', 'date_time_y', 'day', 'time_step', 'day_s', 'code', 'date_time','return']]\n",
    "#scale those x variables in training dataset\n",
    "scaled_df=scaler.fit_transform(df[col_train])\n",
    "scaled_df=pd.DataFrame(scaled_df,columns=['turnoverRatio', 'transactionAmount', 'pe_ttm', 'pe', 'pb', 'ps', 'pcf','open', 'close', 'high', 'low', 'volume', 'money'])\n",
    "#add timer back to the df\n",
    "new_df=pd.merge(scaled_df,timer_train,how='outer',left_index=True,right_index=True)\n",
    "\n",
    "#same process for test dataset\n",
    "col_test=[i for i in test.columns if i not in ['date_time_x', 'date_time_y', 'day', 'time_step', 'day_s', 'code', 'date_time']]\n",
    "timer_test=test.loc[:,['date_time_x', 'date_time_y', 'day', 'time_step', 'day_s', 'code']]\n",
    "scaled_test=scaler.fit_transform(test[col_test])\n",
    "scaled_test=pd.DataFrame(scaled_test,columns=['turnoverRatio', 'transactionAmount', 'pe_ttm', 'pe', 'pb', 'ps', 'pcf','open', 'close', 'high', 'low', 'volume', 'money'])\n",
    "new_test=pd.merge(scaled_test,timer_test,how='outer',left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turnoverRatio</th>\n",
       "      <th>transactionAmount</th>\n",
       "      <th>pe_ttm</th>\n",
       "      <th>pe</th>\n",
       "      <th>pb</th>\n",
       "      <th>ps</th>\n",
       "      <th>pcf</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>date_time_x</th>\n",
       "      <th>date_time_y</th>\n",
       "      <th>day</th>\n",
       "      <th>time_step</th>\n",
       "      <th>day_s</th>\n",
       "      <th>code</th>\n",
       "      <th>date_time</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093616</td>\n",
       "      <td>0.051792</td>\n",
       "      <td>0.025331</td>\n",
       "      <td>0.046411</td>\n",
       "      <td>0.163548</td>\n",
       "      <td>0.083384</td>\n",
       "      <td>0.948034</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>0.024332</td>\n",
       "      <td>0.024362</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.009410</td>\n",
       "      <td>s0d1</td>\n",
       "      <td>s0d1p50</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>s0d1</td>\n",
       "      <td>s0</td>\n",
       "      <td>s0d1</td>\n",
       "      <td>-0.026877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063802</td>\n",
       "      <td>0.011141</td>\n",
       "      <td>0.025208</td>\n",
       "      <td>0.046202</td>\n",
       "      <td>0.168140</td>\n",
       "      <td>0.065664</td>\n",
       "      <td>0.951514</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.015374</td>\n",
       "      <td>0.015532</td>\n",
       "      <td>0.015375</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>s1d1</td>\n",
       "      <td>s1d1p50</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>s1d1</td>\n",
       "      <td>s1</td>\n",
       "      <td>s1d1</td>\n",
       "      <td>-0.052674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032330</td>\n",
       "      <td>0.015439</td>\n",
       "      <td>0.025523</td>\n",
       "      <td>0.046811</td>\n",
       "      <td>0.158080</td>\n",
       "      <td>0.090780</td>\n",
       "      <td>0.951040</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.007681</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>s2d1</td>\n",
       "      <td>s2d1p50</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>s2d1</td>\n",
       "      <td>s2</td>\n",
       "      <td>s2d1</td>\n",
       "      <td>-0.002691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53889</th>\n",
       "      <td>0.028856</td>\n",
       "      <td>0.015569</td>\n",
       "      <td>0.024882</td>\n",
       "      <td>0.045675</td>\n",
       "      <td>0.019734</td>\n",
       "      <td>0.011614</td>\n",
       "      <td>0.951489</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>s51d998</td>\n",
       "      <td>s51d998p50</td>\n",
       "      <td>998</td>\n",
       "      <td>50</td>\n",
       "      <td>s51d998</td>\n",
       "      <td>s51</td>\n",
       "      <td>s51d998</td>\n",
       "      <td>-0.052286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53890</th>\n",
       "      <td>0.013962</td>\n",
       "      <td>0.022720</td>\n",
       "      <td>0.025208</td>\n",
       "      <td>0.046273</td>\n",
       "      <td>0.197897</td>\n",
       "      <td>0.081012</td>\n",
       "      <td>0.948013</td>\n",
       "      <td>0.029243</td>\n",
       "      <td>0.029194</td>\n",
       "      <td>0.029194</td>\n",
       "      <td>0.029245</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>s52d998</td>\n",
       "      <td>s52d998p50</td>\n",
       "      <td>998</td>\n",
       "      <td>50</td>\n",
       "      <td>s52d998</td>\n",
       "      <td>s52</td>\n",
       "      <td>s52d998</td>\n",
       "      <td>-0.015559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53891</th>\n",
       "      <td>0.032522</td>\n",
       "      <td>0.029102</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.045511</td>\n",
       "      <td>0.043472</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>0.008671</td>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>s53d998</td>\n",
       "      <td>s53d998p50</td>\n",
       "      <td>998</td>\n",
       "      <td>50</td>\n",
       "      <td>s53d998</td>\n",
       "      <td>s53</td>\n",
       "      <td>s53d998</td>\n",
       "      <td>-0.003662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53892 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       turnoverRatio  transactionAmount    pe_ttm        pe        pb  \\\n",
       "0           0.093616           0.051792  0.025331  0.046411  0.163548   \n",
       "1           0.063802           0.011141  0.025208  0.046202  0.168140   \n",
       "2           0.032330           0.015439  0.025523  0.046811  0.158080   \n",
       "...              ...                ...       ...       ...       ...   \n",
       "53889       0.028856           0.015569  0.024882  0.045675  0.019734   \n",
       "53890       0.013962           0.022720  0.025208  0.046273  0.197897   \n",
       "53891       0.032522           0.029102  0.024792  0.045511  0.043472   \n",
       "\n",
       "             ps       pcf      open     close      high       low    volume  \\\n",
       "0      0.083384  0.948034  0.024360  0.024333  0.024332  0.024362  0.004363   \n",
       "1      0.065664  0.951514  0.015426  0.015374  0.015532  0.015375  0.001816   \n",
       "2      0.090780  0.951040  0.007680  0.007667  0.007667  0.007681  0.002155   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "53889  0.011614  0.951489  0.001900  0.001897  0.001897  0.001900  0.004846   \n",
       "53890  0.081012  0.948013  0.029243  0.029194  0.029194  0.029245  0.001526   \n",
       "53891  0.004854  0.952153  0.008670  0.008655  0.008655  0.008671  0.004737   \n",
       "\n",
       "          money date_time_x date_time_y  day time_step    day_s code  \\\n",
       "0      0.009410        s0d1     s0d1p50    1        50     s0d1   s0   \n",
       "1      0.002596        s1d1     s1d1p50    1        50     s1d1   s1   \n",
       "2      0.001721        s2d1     s2d1p50    1        50     s2d1   s2   \n",
       "...         ...         ...         ...  ...       ...      ...  ...   \n",
       "53889  0.001592     s51d998  s51d998p50  998        50  s51d998  s51   \n",
       "53890  0.003895     s52d998  s52d998p50  998        50  s52d998  s52   \n",
       "53891  0.004162     s53d998  s53d998p50  998        50  s53d998  s53   \n",
       "\n",
       "      date_time    return  \n",
       "0          s0d1 -0.026877  \n",
       "1          s1d1 -0.052674  \n",
       "2          s2d1 -0.002691  \n",
       "...         ...       ...  \n",
       "53889   s51d998 -0.052286  \n",
       "53890   s52d998 -0.015559  \n",
       "53891   s53d998 -0.003662  \n",
       "\n",
       "[53892 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-19T11:42:06.156023Z",
     "iopub.status.busy": "2023-02-19T11:42:06.155626Z",
     "iopub.status.idle": "2023-02-19T11:42:06.169707Z",
     "shell.execute_reply": "2023-02-19T11:42:06.168505Z",
     "shell.execute_reply.started": "2023-02-19T11:42:06.155992Z"
    },
    "id": "jhkIqDnLpJqD"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(train,test):\n",
    "    # Hyperparammeters (just basic)\n",
    "    params = {\n",
    "      'objective': 'rmse',  \n",
    "      'boosting_type': 'gbdt',\n",
    "      'n_jobs': -1,\n",
    "      'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Split features and target\n",
    "    \n",
    "    x = train[[i for i in df.columns if i not in ['date_time_x', 'date_time_y', 'day', 'time_step', \n",
    "                                                  'day_s', 'code', 'date_time','return']]]\n",
    "    y = train['return']\n",
    "    \n",
    "    x_test = test[[i for i in df.columns if i not in ['date_time_x', 'date_time_y', 'day', 'time_step', \n",
    "                                                      'day_s', 'code', 'date_time','return']]]\n",
    "\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    test_predictions = np.zeros(x_test.shape[0])\n",
    "    scores = []\n",
    "\n",
    "    # Create a KFold object\n",
    "    gkf = TimeSeriesSplit(n_splits=n_fold,gap=group_gap)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(gkf.split(train['day'].values)):\n",
    "    \n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        \n",
    "        # create and fit the LSTM network\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=64, return_sequences=True,dropout=0.1,recurrent_dropout=0.1,input_shape=(x_train.shape[1],1)))\n",
    "        model.add(LSTM(units=32))\n",
    "        model.add(Dense(1))\n",
    " \n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics='mae')\n",
    "        model.fit(x_train, y_train, epochs=1, batch_size=1024, verbose=2)\n",
    "        \n",
    "        #This train_pred must have the same shape as the dataset on which you fitted the scaler. \n",
    "        #To do the inverse_transform you can extract the needed attributes from your scaler \n",
    "        #and apply them to your prediction.\n",
    "        scaler_pred=MinMaxScaler()\n",
    "        scaler_pred.min_, scaler_pred.scale_ = scaler.min_[1], scaler.scale_[1]\n",
    "        \n",
    "        #calculate validation prediction\n",
    "        whole_pred=model.predict(x)\n",
    "        whole_pred=np.reshape(whole_pred,(whole_pred.shape[0],))\n",
    "        oof_predictions[val_ind] = whole_pred[val_ind] \n",
    "        rmspe_score = corr_score(y_val,oof_predictions[val_ind])\n",
    "        print(f'Our out of folds corr_score is {rmspe_score}')\n",
    "        scores.append(rmspe_score)\n",
    "        \n",
    "        #calculate test prediction\n",
    "        test_pred=model.predict(x_test)\n",
    "        test_pred=np.reshape(test_pred,(test_pred.shape[0],))\n",
    "        test_predictions = test_predictions + test_pred\n",
    "                \n",
    "        #clear session\n",
    "        keras.backend.clear_session()\n",
    "        del model\n",
    "        \n",
    "    rmspe_score = corr_score(y, oof_predictions)\n",
    "    print(scores)\n",
    "    print(f'Our out of folds corr score is {rmspe_score}')\n",
    "    \n",
    "    # Return test predictions\n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-02-19T11:42:06.401036Z",
     "iopub.status.busy": "2023-02-19T11:42:06.400583Z",
     "iopub.status.idle": "2023-02-19T11:42:08.132067Z",
     "shell.execute_reply": "2023-02-19T11:42:08.131046Z",
     "shell.execute_reply.started": "2023-02-19T11:42:06.401001Z"
    },
    "id": "s2MYJdoEpJqD",
    "outputId": "bce4f8ed-9413-4f63-8fff-6d27f951369e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1\n",
      "5/5 - 11s - loss: 0.0018 - mae: 0.0316 - 11s/epoch - 2s/step\n",
      "Our out of folds corr_score is 0.0011785387779088866\n",
      "Training fold 2\n",
      "10/10 - 13s - loss: 0.0046 - mae: 0.0488 - 13s/epoch - 1s/step\n",
      "Our out of folds corr_score is -0.0042531559663210265\n",
      "Training fold 3\n",
      "15/15 - 14s - loss: 0.0039 - mae: 0.0448 - 14s/epoch - 924ms/step\n",
      "Our out of folds corr_score is 0.002959785528850635\n",
      "Training fold 4\n",
      "20/20 - 16s - loss: 0.0033 - mae: 0.0406 - 16s/epoch - 824ms/step\n",
      "Our out of folds corr_score is 0.06325872877068725\n",
      "Training fold 5\n",
      "24/24 - 17s - loss: 0.0027 - mae: 0.0359 - 17s/epoch - 689ms/step\n",
      "Our out of folds corr_score is 0.010199215227483968\n",
      "Training fold 6\n",
      "29/29 - 23s - loss: 0.0025 - mae: 0.0343 - 23s/epoch - 786ms/step\n",
      "Our out of folds corr_score is 0.020433227915653284\n",
      "Training fold 7\n",
      "34/34 - 23s - loss: 0.0022 - mae: 0.0315 - 23s/epoch - 684ms/step\n",
      "Our out of folds corr_score is -0.039400779248146466\n",
      "Training fold 8\n",
      "39/39 - 24s - loss: 0.0020 - mae: 0.0306 - 24s/epoch - 615ms/step\n",
      "Our out of folds corr_score is -0.0031900932551858227\n",
      "Training fold 9\n",
      "44/44 - 27s - loss: 0.0019 - mae: 0.0296 - 27s/epoch - 614ms/step\n",
      "Our out of folds corr_score is 0.01838002581449267\n",
      "Training fold 10\n",
      "48/48 - 29s - loss: 0.0019 - mae: 0.0295 - 29s/epoch - 614ms/step\n",
      "Our out of folds corr_score is 0.0033643023332057703\n",
      "[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.02443480e-04\n",
      " -1.43360448e-05  1.56377238e-04]\n",
      "[0.0011785387779088866, -0.0042531559663210265, 0.002959785528850635, 0.06325872877068725, 0.010199215227483968, 0.020433227915653284, -0.039400779248146466, -0.0031900932551858227, 0.01838002581449267, 0.0033643023332057703]\n",
      "Our out of folds corr score is 0.0008784504407991785\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = train_and_evaluate(new_df,new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01946763, 0.01894294, 0.01865841, ..., 0.01954658, 0.01748274,\n",
       "       0.01999011])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-19T11:42:08.145003Z",
     "iopub.status.busy": "2023-02-19T11:42:08.144544Z",
     "iopub.status.idle": "2023-02-19T11:42:08.25156Z",
     "shell.execute_reply": "2023-02-19T11:42:08.250527Z",
     "shell.execute_reply.started": "2023-02-19T11:42:08.144966Z"
    },
    "id": "TGGyX9skpJqD"
   },
   "outputs": [],
   "source": [
    "# Save test predictions\n",
    "test['return'] = test_predictions\n",
    "\n",
    "prediction = test[['date_time_x','return']]\n",
    "prediction.columns=['date_time','return']\n",
    "prediction.to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NA8tjThw0EyC"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(20230304)\n",
    "\n",
    "SUBMISSION_PATH = '/kaggle/working/submission.csv'\n",
    "\n",
    "POINT_PER_DAY = 50\n",
    "\n",
    "class QIDS:\n",
    "    def __init__(self) -> None:\n",
    "        self.__submission_path = SUBMISSION_PATH\n",
    "        self.__current_idx = 0\n",
    "        self.__predict_idx = 0\n",
    "        self.__num_of_stocks = 54\n",
    "        self.__point_per_day = POINT_PER_DAY\n",
    "        self.__end = False\n",
    "        self.__current_fundamental_df = None\n",
    "\n",
    "        self.__fundamental_df = pd.read_csv(TEST_FUNADMENTAL_PATH)\n",
    "        self.__market_df = pd.read_csv(TEST_MARKET_PATH)\n",
    "        \n",
    "        if len(self.__fundamental_df) / self.__num_of_stocks != len(self.__market_df)/ self.__num_of_stocks / self.__point_per_day:\n",
    "            raise ValueError('The length of fundamental data and market data is not equal.')\n",
    "        self.__length = len(self.__fundamental_df) / self.__num_of_stocks\n",
    "\n",
    "        with open(self.__submission_path, 'w') as f:\n",
    "            f.write('date_time,return\\n') \n",
    "        \n",
    "        print('Environment is initialized.')\n",
    "    \n",
    "    def is_end(self):\n",
    "        return self.__end\n",
    "\n",
    "    # return the fun\n",
    "    def get_current_market(self):\n",
    "        if self.__end:\n",
    "            raise ValueError('The environment has ended.')\n",
    "\n",
    "        # check if the current index is equal to the predict index\n",
    "        if self.__current_idx != self.__predict_idx:\n",
    "            raise ValueError('The current index is not equal to the predict index.')\n",
    "\n",
    "        # load data of the current day\n",
    "        fundamental_df = self.__fundamental_df.iloc[self.__current_idx * self.__num_of_stocks: (self.__current_idx + 1) * self.__num_of_stocks]\n",
    "        market_df = self.__market_df.iloc[self.__current_idx * self.__num_of_stocks * self.__point_per_day: (self.__current_idx + 1) * self.__num_of_stocks * self.__point_per_day]\n",
    "        \n",
    "        # update the current index\n",
    "        self.__current_idx += 1\n",
    "        self.__current_fundamental_df = fundamental_df.reset_index()\n",
    "        \n",
    "        return fundamental_df, market_df\n",
    "\n",
    "    def input_prediction(self, predict_ds: pd.Series):\n",
    "        if self.__end:\n",
    "            raise ValueError('The environment has ended.')\n",
    "\n",
    "        # check if the current index is equal to the predict index plus 1\n",
    "        if self.__current_idx != self.__predict_idx + 1:\n",
    "            raise ValueError('The current index is not equal to the predict index plus 1.')\n",
    "\n",
    "        # check the length of the predict_ds\n",
    "        if len(predict_ds) != self.__num_of_stocks:\n",
    "            raise ValueError('The length of input decisions is wrong.')\n",
    "        \n",
    "        # check the type of the predict_ds\n",
    "        if type(predict_ds) != pd.Series:\n",
    "            raise TypeError('The type of input decisions is wrong.')\n",
    "        \n",
    "        # write the prediction to the submission file\n",
    "        with open(self.__submission_path, 'a') as f:\n",
    "            for idx in range(len(predict_ds)):\n",
    "                f.write(f\"{str(self.__current_fundamental_df['date_time'][idx])},{str(predict_ds.iloc[idx])}\\n\")\n",
    "\n",
    "                # must follow the stock order\n",
    "                # f.write(f\"s{idx}d{self.__current_idx},{str(predict_ds.iloc[idx])}\\n\")\n",
    "        \n",
    "        self.__predict_idx += 1\n",
    "        if self.__predict_idx == self.__length:\n",
    "            self.__end = True\n",
    "            print('Data Feeding is finished.')\n",
    "        \n",
    "\n",
    "# initialize the environment\n",
    "def make_env():\n",
    "    if random.random() == 0.8396457911824297:\n",
    "        return QIDS()\n",
    "    else:\n",
    "        raise ImportError('You cannot make this environment twice.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "-7TOxUH4pJqD",
    "outputId": "ee0fd5dd-62f2-4b4a-f3ee-db9deadf51de"
   },
   "outputs": [],
   "source": [
    "#from qids_package.qids import *\n",
    "\n",
    "env = make_env()\n",
    "\n",
    "import random \n",
    "random.seed(42)\n",
    "\n",
    "while not env.is_end():\n",
    "\tfundamental_df, market_df = env.get_current_market()\n",
    "\t\n",
    "\tl = []\n",
    "\tfor idx in range(54):\n",
    "\t\tl.append(random.random())\n",
    "\tpredict_ds =pd.Series(1)\n",
    "\t\n",
    "\tenv.input_prediction(predict_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-19T11:42:06.156023Z",
     "iopub.status.busy": "2023-02-19T11:42:06.155626Z",
     "iopub.status.idle": "2023-02-19T11:42:06.169707Z",
     "shell.execute_reply": "2023-02-19T11:42:06.168505Z",
     "shell.execute_reply.started": "2023-02-19T11:42:06.155992Z"
    },
    "id": "jhkIqDnLpJqD"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(train,test):\n",
    "    # Hyperparammeters (just basic)\n",
    "    params = {\n",
    "      'objective': 'rmse',  \n",
    "      'boosting_type': 'gbdt',\n",
    "      'n_jobs': -1,\n",
    "      'verbose': -1\n",
    "    }\n",
    "    \n",
    "    # Split features and target\n",
    "    \n",
    "    x = train[[i for i in df.columns if i not in ['date_time_x', 'date_time_y', 'day', 'time_step', 'day_s', 'code', 'date_time','return']]]\n",
    "    y = train['return']\n",
    "    \n",
    "    x_test = test[[i for i in df.columns if i not in ['date_time_x', 'date_time_y', 'day', 'time_step', 'day_s', 'code', 'date_time','return']]]\n",
    "\n",
    "    oof_predictions = np.zeros(x.shape[0])\n",
    "    test_predictions = np.zeros(x_test.shape[0])\n",
    "    scores = []\n",
    "\n",
    "    # Create a KFold object\n",
    "    gkf = TimeSeriesSplit(n_splits=n_fold,gap=group_gap)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(gkf.split(train['day'].values)):\n",
    "    \n",
    "        print(f'Training fold {fold + 1}')\n",
    "        x_train, x_val = x.iloc[trn_ind], x.iloc[val_ind]\n",
    "        y_train, y_val = y.iloc[trn_ind], y.iloc[val_ind]\n",
    "        \n",
    "        #这下面的用到lgb了\n",
    "        train_dataset = lgb.Dataset(x_train, y_train)\n",
    "        val_dataset = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(params = params, \n",
    "                          train_set = train_dataset, \n",
    "                          valid_sets = [train_dataset, val_dataset], \n",
    "                          num_boost_round = 200, \n",
    "                          early_stopping_rounds = 20, \n",
    "                          verbose_eval = False,\n",
    "                          feval = correlation)\n",
    "        # Add predictions to the out of folds array\n",
    "        \n",
    "        oof_predictions[val_ind] = model.predict(x_val)\n",
    "        \n",
    "        rmspe_score = corr_score(y_val,oof_predictions[val_ind])\n",
    "        print(f'Our out of folds corr_score is {rmspe_score}')\n",
    "        scores.append(rmspe_score)\n",
    "        test_predictions += model.predict(x_test) \n",
    "        \n",
    "    rmspe_score = corr_score(y, oof_predictions)\n",
    "    print(scores)\n",
    "    print(f'Our out of folds corr score is {rmspe_score}')\n",
    "    \n",
    "    # Return test predictions\n",
    "    return test_predictions"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
